<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><script></script><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3"><link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222"><meta name="keywords" content="Python,爬虫,搜索引擎,Scrapy,"><link rel="alternate" href="/atom.xml" title="mtianyan's blog" type="application/atom+xml"><meta name="description" content="知乎网问题和答案爬取   对于知乎进行模拟登录以及验证码的处理,对于两种不同新旧样式进行区分。数据库建表将爬取的问题与答案存入数据库"><meta name="keywords" content="Python,爬虫,搜索引擎,Scrapy"><meta property="og:type" content="article"><meta property="og:title" content="Scrapy分布式爬虫打造搜索引擎- (三)知乎网问题和答案爬取"><meta property="og:url" content="http://blog.mtianyan.cn/post/b9bf70b2.html"><meta property="og:site_name" content="mtianyan&#39;s blog"><meta property="og:description" content="知乎网问题和答案爬取   对于知乎进行模拟登录以及验证码的处理,对于两种不同新旧样式进行区分。数据库建表将爬取的问题与答案存入数据库"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-f01f9c33e578427d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-e5d75b510a604f78.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-31ff3c83ea890269.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-cf6b7ac1027726fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-e972fd3af04fc8f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-ce3f15b285ed1e64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-4be3a480d6f73679.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-942806c2e9ed83cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1779926-c12492078a2369f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><meta property="og:updated_time" content="2018-01-05T22:34:48.030Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Scrapy分布式爬虫打造搜索引擎- (三)知乎网问题和答案爬取"><meta name="twitter:description" content="知乎网问题和答案爬取   对于知乎进行模拟登录以及验证码的处理,对于两种不同新旧样式进行区分。数据库建表将爬取的问题与答案存入数据库"><meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/1779926-f01f9c33e578427d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"5.1.3",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://blog.mtianyan.cn/post/b9bf70b2.html"><script>!function(e,t,o,c,i,a,n){e.DaoVoiceObject=i,e[i]=e[i]||function(){(e[i].q=e[i].q||[]).push(arguments)},e[i].l=1*new Date,a=t.createElement("script"),n=t.getElementsByTagName("script")[0],a.async=1,a.src=c,a.charset="utf-8",n.parentNode.insertBefore(a,n)}(window,document,0,("https:"==document.location.protocol?"https:":"http:")+"//widget.daovoice.io/widget/0f81ff2f.js","daovoice"),daovoice("init",{app_id:"e28768be"}),daovoice("update")</script><title>Scrapy分布式爬虫打造搜索引擎- (三)知乎网问题和答案爬取 | mtianyan's blog</title><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?415372bd35fec36f7558dd96b48ec03f";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div> <a href="https://github.com/mtianyan" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513;color:#fff;position:absolute;top:0;border:0;right:0" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">mtianyan's blog</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">天涯明月笙的博客小站(Github托管)</p></div><div class="site-nav-toggle"> <button><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br> 归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br> 公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br> 搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"> <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://blog.mtianyan.cn/post/b9bf70b2.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="mtianyan"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="mtianyan's blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Scrapy分布式爬虫打造搜索引擎- (三)知乎网问题和答案爬取</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-28T14:58:24+08:00">2017-06-28</time></span> <span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Scrapy分布式爬虫打造搜索引擎/" itemprop="url" rel="index"><span itemprop="name">Scrapy分布式爬虫打造搜索引擎</span></a></span></span> <span id="/post/b9bf70b2.html" class="leancloud_visitors" data-flag-title="Scrapy分布式爬虫打造搜索引擎- (三)知乎网问题和答案爬取"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">热度&#58;</span><span class="leancloud-visitors-count"></span> <span>℃</span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">3,385</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">18</span></div></div></header><div class="post-body" itemprop="articleBody"><blockquote class="blockquote-center"><p>知乎网问题和答案爬取</p></blockquote><div class="note default"><p> 对于知乎进行模拟登录以及验证码的处理,对于两种不同新旧样式进行区分。<br>数据库建表将爬取的问题与答案存入数据库</p></div><a id="more"></a><h3 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1. 基础知识"></a>1. 基础知识</h3><h4 id="session和cookie机制"><a href="#session和cookie机制" class="headerlink" title="session和cookie机制"></a>session和cookie机制</h4><blockquote><p>cookie：<br>浏览器支持的存储方式<br>key-value</p><p>http无状态请求，两次请求没有联系</p></blockquote><p><img src="http://upload-images.jianshu.io/upload_images/1779926-f01f9c33e578427d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="50%" height="50%"></p><p>session的工作原理</p><p>（1）当一个session第一次被启用时，一个唯一的标识被存储于本地的cookie中。</p><p>（2）首先使用session_start()函数，从session仓库中加载已经存储的session变量。</p><p>（3）通过使用session_register()函数注册session变量。</p><p>（4）脚本执行结束时，未被销毁的session变量会被自动保存在本地一定路径下的session库中.</p><h4 id="request模拟知乎的登录"><a href="#request模拟知乎的登录" class="headerlink" title="request模拟知乎的登录"></a>request模拟知乎的登录</h4><p><strong>http状态码</strong></p><p><img src="http://upload-images.jianshu.io/upload_images/1779926-e5d75b510a604f78.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" width="50%" height="50%"></p><p><strong>获取crsftoken</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_xsrf</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#获取xsrf code</span></span><br><span class="line">    response = requests.get(<span class="string">"https://www.zhihu.com"</span>,headers =header)</span><br><span class="line">    <span class="comment"># # print(response.text)</span></span><br><span class="line">    <span class="comment"># text ='&lt;input type="hidden" name="_xsrf" value="ca70366e5de5d133c3ae09fb16d9b0fa"/&gt;'</span></span><br><span class="line">    match_obj = re.match(<span class="string">'.*name="_xsrf" value="(.*?)"'</span>, response.text)</span><br><span class="line">    <span class="keyword">if</span> match_obj:</span><br><span class="line">        <span class="keyword">return</span> (match_obj.group(<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br></pre></td></tr></table></figure><p>python模拟知乎登录代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># _*_ coding: utf-8 _*_</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> cookielib</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">import</span> http.cookiejar <span class="keyword">as</span> cookielib</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">__author__ = <span class="string">'mtianyan'</span></span><br><span class="line">__date__ = <span class="string">'2017/5/23 16:42'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> cookielib</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">import</span> http.cookiejar <span class="keyword">as</span> cookielib</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">session = requests.session()</span><br><span class="line">session.cookies = cookielib.LWPCookieJar(filename=<span class="string">"cookies.txt"</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    session.cookies.load(ignore_discard=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"cookie未能加载"</span>)</span><br><span class="line"></span><br><span class="line">agent = <span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.104 Safari/537.36"</span></span><br><span class="line">header = &#123;</span><br><span class="line">    <span class="string">"HOST"</span>:<span class="string">"www.zhihu.com"</span>,</span><br><span class="line">    <span class="string">"Referer"</span>: <span class="string">"https://www.zhizhu.com"</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: agent</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_login</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#通过个人中心页面返回状态码来判断是否为登录状态</span></span><br><span class="line">    inbox_url = <span class="string">"https://www.zhihu.com/question/56250357/answer/148534773"</span></span><br><span class="line">    response = session.get(inbox_url, headers=header, allow_redirects=<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">if</span> response.status_code != <span class="number">200</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_xsrf</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment">#获取xsrf code</span></span><br><span class="line">    response = session.get(<span class="string">"https://www.zhihu.com"</span>, headers=header)</span><br><span class="line">    response_text = response.text</span><br><span class="line">    <span class="comment">#reDOTAll 匹配全文</span></span><br><span class="line">    match_obj = re.match(<span class="string">'.*name="_xsrf" value="(.*?)"'</span>, response_text, re.DOTALL)</span><br><span class="line">    xsrf = <span class="string">''</span></span><br><span class="line">    <span class="keyword">if</span> match_obj:</span><br><span class="line">        xsrf = (match_obj.group(<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> xsrf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_index</span><span class="params">()</span>:</span></span><br><span class="line">    response = session.get(<span class="string">"https://www.zhihu.com"</span>, headers=header)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"index_page.html"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(response.text.encode(<span class="string">"utf-8"</span>))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"ok"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_captcha</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    t = str(int(time.time()*<span class="number">1000</span>))</span><br><span class="line">    captcha_url = <span class="string">"https://www.zhihu.com/captcha.gif?r=&#123;0&#125;&amp;type=login"</span>.format(t)</span><br><span class="line">    t = session.get(captcha_url, headers=header)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"captcha.jpg"</span>,<span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(t.content)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        im = Image.open(<span class="string">'captcha.jpg'</span>)</span><br><span class="line">        im.show()</span><br><span class="line">        im.close()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    captcha = input(<span class="string">"输入验证码\n&gt;"</span>)</span><br><span class="line">    <span class="keyword">return</span> captcha</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zhihu_login</span><span class="params">(account, password)</span>:</span></span><br><span class="line">    <span class="comment">#知乎登录</span></span><br><span class="line">    <span class="keyword">if</span> re.match(<span class="string">"^1\d&#123;10&#125;"</span>,account):</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"手机号码登录"</span>)</span><br><span class="line">        post_url = <span class="string">"https://www.zhihu.com/login/phone_num"</span></span><br><span class="line">        post_data = &#123;</span><br><span class="line">            <span class="string">"_xsrf"</span>: get_xsrf(),</span><br><span class="line">            <span class="string">"phone_num"</span>: account,</span><br><span class="line">            <span class="string">"password"</span>: password,</span><br><span class="line">            <span class="string">"captcha"</span>:get_captcha()</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="string">"@"</span> <span class="keyword">in</span> account:</span><br><span class="line">            <span class="comment">#判断用户名是否为邮箱</span></span><br><span class="line">            print(<span class="string">"邮箱方式登录"</span>)</span><br><span class="line">            post_url = <span class="string">"https://www.zhihu.com/login/email"</span></span><br><span class="line">            post_data = &#123;</span><br><span class="line">                <span class="string">"_xsrf"</span>: get_xsrf(),</span><br><span class="line">                <span class="string">"email"</span>: account,</span><br><span class="line">                <span class="string">"password"</span>: password</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">    response_text = session.post(post_url, data=post_data, headers=header)</span><br><span class="line">    session.cookies.save()</span><br><span class="line"></span><br><span class="line"><span class="comment"># get_index()</span></span><br><span class="line"><span class="comment"># is_login()</span></span><br><span class="line"><span class="comment"># get_captcha()</span></span><br><span class="line">zhihu_login(<span class="string">"phone"</span>, <span class="string">"mima"</span>)</span><br></pre></td></tr></table></figure><h3 id="2-scrapy创建知乎爬虫登录"><a href="#2-scrapy创建知乎爬虫登录" class="headerlink" title="2. scrapy创建知乎爬虫登录"></a>2. scrapy创建知乎爬虫登录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider zhihu www.zhihu.com</span><br></pre></td></tr></table></figure><p>因为知乎我们需要先进行登录，所以我们重写它的start_requests</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [scrapy.Request(<span class="string">'https://www.zhihu.com/#signin'</span>, headers=self.headers, callback=self.login)]</span><br></pre></td></tr></table></figure><ol><li><p>下载首页然后回调login函数。</p></li><li><p>login函数请求验证码并回调login_after_captcha函数.此处通过meta将post_data传送出去，后面的回调函数来用。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    response_text = response.text</span><br><span class="line">    <span class="comment">#获取xsrf。</span></span><br><span class="line">    match_obj = re.match(<span class="string">'.*name="_xsrf" value="(.*?)"'</span>, response_text, re.DOTALL)</span><br><span class="line">    xsrf = <span class="string">''</span></span><br><span class="line">    <span class="keyword">if</span> match_obj:</span><br><span class="line">        xsrf = (match_obj.group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> xsrf:</span><br><span class="line">        post_url = <span class="string">"https://www.zhihu.com/login/phone_num"</span></span><br><span class="line">        post_data = &#123;</span><br><span class="line">            <span class="string">"_xsrf"</span>: xsrf,</span><br><span class="line">            <span class="string">"phone_num"</span>: <span class="string">"phone"</span>,</span><br><span class="line">            <span class="string">"password"</span>: <span class="string">"mima"</span>,</span><br><span class="line">            <span class="string">"captcha"</span>: <span class="string">""</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">import</span> time</span><br><span class="line">        t = str(int(time.time() * <span class="number">1000</span>))</span><br><span class="line">        captcha_url = <span class="string">"https://www.zhihu.com/captcha.gif?r=&#123;0&#125;&amp;type=login"</span>.format(t)</span><br><span class="line">        <span class="comment">#请求验证码并回调login_after_captcha.</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(captcha_url, headers=self.headers, </span><br><span class="line">            meta=&#123;<span class="string">"post_data"</span>:post_data&#125;, callback=self.login_after_captcha)</span><br></pre></td></tr></table></figure><ol><li>login_after_captcha函数将验证码图片保存到本地，然后使用PIL库打开图片，肉眼识别后在控制台输入验证码值<br>然后接受步骤一的meta数据，一并提交至登录接口。回调check_login检查是否登录成功。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login_after_captcha</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"captcha.jpg"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(response.body)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        im = Image.open(<span class="string">'captcha.jpg'</span>)</span><br><span class="line">        im.show()</span><br><span class="line">        im.close()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    captcha = input(<span class="string">"输入验证码\n&gt;"</span>)</span><br><span class="line"></span><br><span class="line">    post_data = response.meta.get(<span class="string">"post_data"</span>, &#123;&#125;)</span><br><span class="line">    post_url = <span class="string">"https://www.zhihu.com/login/phone_num"</span></span><br><span class="line">    post_data[<span class="string">"captcha"</span>] = captcha</span><br><span class="line">    <span class="keyword">return</span> [scrapy.FormRequest(</span><br><span class="line">        url=post_url,</span><br><span class="line">        formdata=post_data,</span><br><span class="line">        headers=self.headers,</span><br><span class="line">        callback=self.check_login</span><br><span class="line">    )]</span><br></pre></td></tr></table></figure><ol><li>check_login函数，验证服务器的返回数据判断是否成功<br>scrapy会对request的URL去重(RFPDupeFilter)，加上dont_filter则告诉它这个URL不参与去重.</li></ol><p>源码中的startrequest:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">        <span class="keyword">yield</span> self.make_requests_from_url(url)</span><br></pre></td></tr></table></figure><p>我们将原本的start_request的代码放在了现在重写的，回调链最后的check_login</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_login</span><span class="params">(self, response)</span>:</span></span><br><span class="line">       <span class="comment">#验证服务器的返回数据判断是否成功</span></span><br><span class="line">       text_json = json.loads(response.text)</span><br><span class="line">       <span class="keyword">if</span> <span class="string">"msg"</span> <span class="keyword">in</span> text_json <span class="keyword">and</span> text_json[<span class="string">"msg"</span>] == <span class="string">"登录成功"</span>:</span><br><span class="line">           <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</span><br><span class="line">               <span class="keyword">yield</span> scrapy.Request(url, dont_filter=<span class="keyword">True</span>, headers=self.headers)</span><br></pre></td></tr></table></figure><p><img src="http://upload-images.jianshu.io/upload_images/1779926-31ff3c83ea890269.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="登录代码流程"></p><p>###3. 知乎数据表设计<br><img src="http://upload-images.jianshu.io/upload_images/1779926-cf6b7ac1027726fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="知乎答案版本1"></p><blockquote><p>上图为知乎答案版本1</p></blockquote><p><img src="http://upload-images.jianshu.io/upload_images/1779926-e972fd3af04fc8f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="知乎答案版本2"></p><blockquote><p>上图为知乎答案版本2</p></blockquote><p><strong>设置数据表字段</strong></p><table><thead><tr><th>问题字段</th><th style="text-align:center">回答字段</th></tr></thead><tbody><tr><td>zhihu_id</td><td style="text-align:center">zhihu_id</td></tr><tr><td>topics</td><td style="text-align:center">url</td></tr><tr><td>url</td><td style="text-align:center">question_id</td></tr><tr><td>title</td><td style="text-align:center">author_id</td></tr><tr><td>content</td><td style="text-align:center">content</td></tr><tr><td>answer_num</td><td style="text-align:center">parise_num</td></tr><tr><td>comments_num</td><td style="text-align:center">comments_num</td></tr><tr><td>watch_user_num</td><td style="text-align:center">create_time</td></tr><tr><td>click_num</td><td style="text-align:center">update_time</td></tr><tr><td>crawl_time</td><td style="text-align:center">crawl_time</td></tr></tbody></table><p><img src="http://upload-images.jianshu.io/upload_images/1779926-ce3f15b285ed1e64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="知乎问题表"></p><p><img src="http://upload-images.jianshu.io/upload_images/1779926-4be3a480d6f73679.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="知乎答案表"></p><p><strong>知乎url分析</strong></p><p>点具体问题下查看更多。<br>可获得接口：</p><blockquote><p><a href="https://www.zhihu.com/api/v4/questions/25914034/answers?include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Creview_info%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=43&amp;sort_by=default" target="_blank" rel="noopener">https://www.zhihu.com/api/v4/questions/25914034/answers?include=data%5B%2A%5D.is_normal%2Cis_collapsed%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Cmark_infos%2Ccreated_time%2Cupdated_time%2Creview_info%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=20&amp;offset=43&amp;sort_by=default</a></p></blockquote><p><strong>重点参数：</strong><br><code>offset=43</code><br><code>isend = true</code><br><code>next</code><br><img src="http://upload-images.jianshu.io/upload_images/1779926-942806c2e9ed83cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="点击更多接口返回"></p><p><strong>href=”/question/25460323”</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_urls = [parse.urljoin(response.url, url) <span class="keyword">for</span> url <span class="keyword">in</span> all_urls]</span><br></pre></td></tr></table></figure><ol><li>从首页获取所有a标签。如果提取的url中格式为 /question/xxx 就下载之后直接进入解析函数parse_question<br>如果不是question页面则直接进一步跟踪。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">            提取出html页面中的所有url 并跟踪这些url进行一步爬取</span></span><br><span class="line"><span class="string">            如果提取的url中格式为 /question/xxx 就下载之后直接进入解析函数</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">    all_urls = response.css(<span class="string">"a::attr(href)"</span>).extract()</span><br><span class="line">    all_urls = [parse.urljoin(response.url, url) <span class="keyword">for</span> url <span class="keyword">in</span> all_urls]</span><br><span class="line">    <span class="comment">#使用lambda函数对于每一个url进行过滤，如果是true放回列表，返回false去除。</span></span><br><span class="line">    all_urls = filter(<span class="keyword">lambda</span> x:<span class="keyword">True</span> <span class="keyword">if</span> x.startswith(<span class="string">"https"</span>) <span class="keyword">else</span> <span class="keyword">False</span>, all_urls)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> all_urls:</span><br><span class="line">        match_obj = re.match(<span class="string">"(.*zhihu.com/question/(\d+))(/|$).*"</span>, url)</span><br><span class="line">        <span class="keyword">if</span> match_obj:</span><br><span class="line">            <span class="comment"># 如果提取到question相关的页面则下载后交由提取函数进行提取</span></span><br><span class="line">            request_url = match_obj.group(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(request_url, headers=self.headers, callback=self.parse_question)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果不是question页面则直接进一步跟踪</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, headers=self.headers, callback=self.parse)</span><br></pre></td></tr></table></figure><ol><li>进入parse_question函数处理<br><strong>创建我们的item</strong></li></ol><p>item要用到的方法ArticleSpider\utils\common.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_num</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="comment">#从字符串中提取出数字</span></span><br><span class="line">    match_re = re.match(<span class="string">".*?(\d+).*"</span>, text)</span><br><span class="line">    <span class="keyword">if</span> match_re:</span><br><span class="line">        nums = int(match_re.group(<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        nums = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><p>setting.py中设置<br><code>SQL_DATETIME_FORMAT = &quot;%Y-%m-%d %H:%M:%S&quot; SQL_DATE_FORMAT = &quot;%Y-%m-%d&quot;</code><br>使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ArticleSpider.settings <span class="keyword">import</span> SQL_DATETIME_FORMAT</span><br></pre></td></tr></table></figure><p><strong>知乎的问题 item</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhihuQuestionItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment">#知乎的问题 item</span></span><br><span class="line">    zhihu_id = scrapy.Field()</span><br><span class="line">    topics = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br><span class="line">    answer_num = scrapy.Field()</span><br><span class="line">    comments_num = scrapy.Field()</span><br><span class="line">    watch_user_num = scrapy.Field()</span><br><span class="line">    click_num = scrapy.Field()</span><br><span class="line">    crawl_time = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_insert_sql</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#插入知乎question表的sql语句</span></span><br><span class="line">        insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">            insert into zhihu_question(zhihu_id, topics, url, title, content, answer_num, comments_num,</span></span><br><span class="line"><span class="string">              watch_user_num, click_num, crawl_time</span></span><br><span class="line"><span class="string">              )</span></span><br><span class="line"><span class="string">            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)</span></span><br><span class="line"><span class="string">            ON DUPLICATE KEY UPDATE content=VALUES(content), answer_num=VALUES(answer_num), comments_num=VALUES(comments_num),</span></span><br><span class="line"><span class="string">              watch_user_num=VALUES(watch_user_num), click_num=VALUES(click_num)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        zhihu_id = self[<span class="string">"zhihu_id"</span>][<span class="number">0</span>]</span><br><span class="line">        topics = <span class="string">","</span>.join(self[<span class="string">"topics"</span>])</span><br><span class="line">        url = self[<span class="string">"url"</span>][<span class="number">0</span>]</span><br><span class="line">        title = <span class="string">""</span>.join(self[<span class="string">"title"</span>])</span><br><span class="line">        content = <span class="string">""</span>.join(self[<span class="string">"content"</span>])</span><br><span class="line">        answer_num = extract_num(<span class="string">""</span>.join(self[<span class="string">"answer_num"</span>]))</span><br><span class="line">        comments_num = extract_num(<span class="string">""</span>.join(self[<span class="string">"comments_num"</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(self[<span class="string">"watch_user_num"</span>]) == <span class="number">2</span>:</span><br><span class="line">            watch_user_num = int(self[<span class="string">"watch_user_num"</span>][<span class="number">0</span>])</span><br><span class="line">            click_num = int(self[<span class="string">"watch_user_num"</span>][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            watch_user_num = int(self[<span class="string">"watch_user_num"</span>][<span class="number">0</span>])</span><br><span class="line">            click_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        crawl_time = datetime.datetime.now().strftime(SQL_DATETIME_FORMAT)</span><br><span class="line"></span><br><span class="line">        params = (zhihu_id, topics, url, title, content, answer_num, comments_num,</span><br><span class="line">                  watch_user_num, click_num, crawl_time)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> insert_sql, params</span><br></pre></td></tr></table></figure><p><strong>知乎问题回答item</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhihuAnswerItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment">#知乎的问题回答item</span></span><br><span class="line">    zhihu_id = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    question_id = scrapy.Field()</span><br><span class="line">    author_id = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br><span class="line">    parise_num = scrapy.Field()</span><br><span class="line">    comments_num = scrapy.Field()</span><br><span class="line">    create_time = scrapy.Field()</span><br><span class="line">    update_time = scrapy.Field()</span><br><span class="line">    crawl_time = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_insert_sql</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#插入知乎question表的sql语句</span></span><br><span class="line">        insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">            insert into zhihu_answer(zhihu_id, url, question_id, author_id, content, parise_num, comments_num,</span></span><br><span class="line"><span class="string">              create_time, update_time, crawl_time</span></span><br><span class="line"><span class="string">              ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)</span></span><br><span class="line"><span class="string">              ON DUPLICATE KEY UPDATE content=VALUES(content), comments_num=VALUES(comments_num), parise_num=VALUES(parise_num),</span></span><br><span class="line"><span class="string">              update_time=VALUES(update_time)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        create_time = datetime.datetime.fromtimestamp(self[<span class="string">"create_time"</span>]).strftime(SQL_DATETIME_FORMAT)</span><br><span class="line">        update_time = datetime.datetime.fromtimestamp(self[<span class="string">"update_time"</span>]).strftime(SQL_DATETIME_FORMAT)</span><br><span class="line">        params = (</span><br><span class="line">            self[<span class="string">"zhihu_id"</span>], self[<span class="string">"url"</span>], self[<span class="string">"question_id"</span>],</span><br><span class="line">            self[<span class="string">"author_id"</span>], self[<span class="string">"content"</span>], self[<span class="string">"parise_num"</span>],</span><br><span class="line">            self[<span class="string">"comments_num"</span>], create_time, update_time,</span><br><span class="line">            self[<span class="string">"crawl_time"</span>].strftime(SQL_DATETIME_FORMAT),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> insert_sql, params</span><br></pre></td></tr></table></figure><p><strong>有了两个item之后，我们继续完善我们的逻辑</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_question</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="comment">#处理question页面， 从页面中提取出具体的question item</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">"QuestionHeader-title"</span> <span class="keyword">in</span> response.text:</span><br><span class="line">        <span class="comment">#处理新版本</span></span><br><span class="line">        match_obj = re.match(<span class="string">"(.*zhihu.com/question/(\d+))(/|$).*"</span>, response.url)</span><br><span class="line">        <span class="keyword">if</span> match_obj:</span><br><span class="line">            question_id = int(match_obj.group(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        item_loader = ItemLoader(item=ZhihuQuestionItem(), response=response)</span><br><span class="line">        item_loader.add_css(<span class="string">"title"</span>, <span class="string">"h1.QuestionHeader-title::text"</span>)</span><br><span class="line">        item_loader.add_css(<span class="string">"content"</span>, <span class="string">".QuestionHeader-detail"</span>)</span><br><span class="line">        item_loader.add_value(<span class="string">"url"</span>, response.url)</span><br><span class="line">        item_loader.add_value(<span class="string">"zhihu_id"</span>, question_id)</span><br><span class="line">        item_loader.add_css(<span class="string">"answer_num"</span>, <span class="string">".List-headerText span::text"</span>)</span><br><span class="line">        item_loader.add_css(<span class="string">"comments_num"</span>, <span class="string">".QuestionHeader-actions button::text"</span>)</span><br><span class="line">        item_loader.add_css(<span class="string">"watch_user_num"</span>, <span class="string">".NumberBoard-value::text"</span>)</span><br><span class="line">        item_loader.add_css(<span class="string">"topics"</span>, <span class="string">".QuestionHeader-topics .Popover div::text"</span>)</span><br><span class="line"></span><br><span class="line">        question_item = item_loader.load_item()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#处理老版本页面的item提取</span></span><br><span class="line">        match_obj = re.match(<span class="string">"(.*zhihu.com/question/(\d+))(/|$).*"</span>, response.url)</span><br><span class="line">        <span class="keyword">if</span> match_obj:</span><br><span class="line">            question_id = int(match_obj.group(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        item_loader = ItemLoader(item=ZhihuQuestionItem(), response=response)</span><br><span class="line">        <span class="comment"># item_loader.add_css("title", ".zh-question-title h2 a::text")</span></span><br><span class="line">        item_loader.add_xpath(<span class="string">"title"</span>, <span class="string">"//*[@id='zh-question-title']/h2/a/text()|//*[@id='zh-question-title']/h2/span/text()"</span>)</span><br><span class="line">        item_loader.add_css(<span class="string">"content"</span>, <span class="string">"#zh-question-detail"</span>)</span><br><span class="line">        item_loader.add_value(<span class="string">"url"</span>, response.url)</span><br><span class="line">        item_loader.add_value(<span class="string">"zhihu_id"</span>, question_id)</span><br><span class="line">        item_loader.add_css(<span class="string">"answer_num"</span>, <span class="string">"#zh-question-answer-num::text"</span>)</span><br><span class="line">        item_loader.add_css(<span class="string">"comments_num"</span>, <span class="string">"#zh-question-meta-wrap a[name='addcomment']::text"</span>)</span><br><span class="line">        <span class="comment"># item_loader.add_css("watch_user_num", "#zh-question-side-header-wrap::text")</span></span><br><span class="line">        item_loader.add_xpath(<span class="string">"watch_user_num"</span>, <span class="string">"//*[@id='zh-question-side-header-wrap']/text()|//*[@class='zh-question-followers-sidebar']/div/a/strong/text()"</span>)</span><br><span class="line">        item_loader.add_css(<span class="string">"topics"</span>, <span class="string">".zm-tag-editor-labels a::text"</span>)</span><br><span class="line"></span><br><span class="line">        question_item = item_loader.load_item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">yield</span> scrapy.Request(self.start_answer_url.format(question_id, <span class="number">20</span>, <span class="number">0</span>), headers=self.headers, callback=self.parse_answer)</span><br><span class="line">    <span class="keyword">yield</span> question_item</span><br></pre></td></tr></table></figure><p><strong>处理问题回答提取出需要的字段</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_answer</span><span class="params">(self, reponse)</span>:</span></span><br><span class="line">    <span class="comment">#处理question的answer</span></span><br><span class="line">    ans_json = json.loads(reponse.text)</span><br><span class="line">    is_end = ans_json[<span class="string">"paging"</span>][<span class="string">"is_end"</span>]</span><br><span class="line">    next_url = ans_json[<span class="string">"paging"</span>][<span class="string">"next"</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#提取answer的具体字段</span></span><br><span class="line">    <span class="keyword">for</span> answer <span class="keyword">in</span> ans_json[<span class="string">"data"</span>]:</span><br><span class="line">        answer_item = ZhihuAnswerItem()</span><br><span class="line">        answer_item[<span class="string">"zhihu_id"</span>] = answer[<span class="string">"id"</span>]</span><br><span class="line">        answer_item[<span class="string">"url"</span>] = answer[<span class="string">"url"</span>]</span><br><span class="line">        answer_item[<span class="string">"question_id"</span>] = answer[<span class="string">"question"</span>][<span class="string">"id"</span>]</span><br><span class="line">        answer_item[<span class="string">"author_id"</span>] = answer[<span class="string">"author"</span>][<span class="string">"id"</span>] <span class="keyword">if</span> <span class="string">"id"</span> <span class="keyword">in</span> answer[<span class="string">"author"</span>] <span class="keyword">else</span> <span class="keyword">None</span></span><br><span class="line">        answer_item[<span class="string">"content"</span>] = answer[<span class="string">"content"</span>] <span class="keyword">if</span> <span class="string">"content"</span> <span class="keyword">in</span> answer <span class="keyword">else</span> <span class="keyword">None</span></span><br><span class="line">        answer_item[<span class="string">"parise_num"</span>] = answer[<span class="string">"voteup_count"</span>]</span><br><span class="line">        answer_item[<span class="string">"comments_num"</span>] = answer[<span class="string">"comment_count"</span>]</span><br><span class="line">        answer_item[<span class="string">"create_time"</span>] = answer[<span class="string">"created_time"</span>]</span><br><span class="line">        answer_item[<span class="string">"update_time"</span>] = answer[<span class="string">"updated_time"</span>]</span><br><span class="line">        answer_item[<span class="string">"crawl_time"</span>] = datetime.datetime.now()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> answer_item</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_end:</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(next_url, headers=self.headers, callback=self.parse_answer)</span><br></pre></td></tr></table></figure><p><strong>知乎提取字段流程图：</strong></p><p><img src="http://upload-images.jianshu.io/upload_images/1779926-c12492078a2369f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="知乎问题及答案提取流程图"></p><p>深度优先：</p><ol><li>提取出页面所有的url，并过滤掉不需要的url</li><li>如果是questionurl就进入question的解析</li><li>把该问题的爬取完了然后就返回初始解析</li></ol><h4 id="将item写入数据库"><a href="#将item写入数据库" class="headerlink" title="将item写入数据库"></a>将item写入数据库</h4><p><strong>pipelines.py错误处理</strong><br>插入时错误可通过该方法监控<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_error</span><span class="params">(self, failure, item, spider)</span>:</span></span><br><span class="line">    <span class="comment">#处理异步插入的异常</span></span><br><span class="line">    <span class="keyword">print</span> (failure)</span><br></pre></td></tr></table></figure><p></p><p><strong>改造pipeline使其变得更通用</strong><br>原本具体硬编码的pipeline</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_insert</span><span class="params">(self, cursor, item)</span>:</span></span><br><span class="line">      <span class="comment">#执行具体的插入</span></span><br><span class="line">      insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">                  insert into jobbole_article(title, url, create_date, fav_nums)</span></span><br><span class="line"><span class="string">                  VALUES (%s, %s, %s, %s)</span></span><br><span class="line"><span class="string">              """</span></span><br><span class="line">      cursor.execute(insert_sql, (item[<span class="string">"title"</span>], item[<span class="string">"url"</span>], item[<span class="string">"create_date"</span>], item[<span class="string">"fav_nums"</span>]))</span><br></pre></td></tr></table></figure><p>改写后的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_insert</span><span class="params">(self, cursor, item)</span>:</span></span><br><span class="line">    <span class="comment">#根据不同的item 构建不同的sql语句并插入到mysql中</span></span><br><span class="line">    insert_sql, params = item.get_insert_sql()</span><br><span class="line">    cursor.execute(insert_sql, params)</span><br></pre></td></tr></table></figure><p>可选方法一：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> item.__class__.__name__ == <span class="string">"JobBoleArticleItem"</span>:</span><br><span class="line">    <span class="comment">#执行具体的插入</span></span><br><span class="line">    insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">                insert into jobbole_article(title, url, create_date, fav_nums)</span></span><br><span class="line"><span class="string">                VALUES (%s, %s, %s, %s)</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">    cursor.execute(insert_sql, (item[<span class="string">"title"</span>], item[<span class="string">"url"</span>], item[<span class="string">"create_date"</span>], item[<span class="string">"fav_nums"</span>]))</span><br></pre></td></tr></table></figure><p>推荐方法：<br>把sql语句等放到item里面：<br>jobboleitem类内部方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_insert_sql</span><span class="params">(self)</span>:</span></span><br><span class="line">    insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">        insert into jobbole_article(title, url, create_date, fav_nums)</span></span><br><span class="line"><span class="string">        VALUES (%s, %s, %s, %s) ON DUPLICATE KEY UPDATE content=VALUES(fav_nums)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    params = (self[<span class="string">"title"</span>], self[<span class="string">"url"</span>], self[<span class="string">"create_date"</span>], self[<span class="string">"fav_nums"</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> insert_sql, params</span><br></pre></td></tr></table></figure><p>知乎问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_insert_sql</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment">#插入知乎question表的sql语句</span></span><br><span class="line">    insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">        insert into zhihu_question(zhihu_id, topics, url, title, content, answer_num, comments_num,</span></span><br><span class="line"><span class="string">          watch_user_num, click_num, crawl_time</span></span><br><span class="line"><span class="string">          )</span></span><br><span class="line"><span class="string">        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)</span></span><br><span class="line"><span class="string">        ON DUPLICATE KEY UPDATE content=VALUES(content), answer_num=VALUES(answer_num), comments_num=VALUES(comments_num),</span></span><br><span class="line"><span class="string">          watch_user_num=VALUES(watch_user_num), click_num=VALUES(click_num)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    zhihu_id = self[<span class="string">"zhihu_id"</span>][<span class="number">0</span>]</span><br><span class="line">    topics = <span class="string">","</span>.join(self[<span class="string">"topics"</span>])</span><br><span class="line">    url = self[<span class="string">"url"</span>][<span class="number">0</span>]</span><br><span class="line">    title = <span class="string">""</span>.join(self[<span class="string">"title"</span>])</span><br><span class="line">    content = <span class="string">""</span>.join(self[<span class="string">"content"</span>])</span><br><span class="line">    answer_num = extract_num(<span class="string">""</span>.join(self[<span class="string">"answer_num"</span>]))</span><br><span class="line">    comments_num = extract_num(<span class="string">""</span>.join(self[<span class="string">"comments_num"</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(self[<span class="string">"watch_user_num"</span>]) == <span class="number">2</span>:</span><br><span class="line">        watch_user_num = int(self[<span class="string">"watch_user_num"</span>][<span class="number">0</span>])</span><br><span class="line">        click_num = int(self[<span class="string">"watch_user_num"</span>][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        watch_user_num = int(self[<span class="string">"watch_user_num"</span>][<span class="number">0</span>])</span><br><span class="line">        click_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    crawl_time = datetime.datetime.now().strftime(SQL_DATETIME_FORMAT)</span><br><span class="line"></span><br><span class="line">    params = (zhihu_id, topics, url, title, content, answer_num, comments_num,</span><br><span class="line">              watch_user_num, click_num, crawl_time)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> insert_sql, params</span><br></pre></td></tr></table></figure><p>知乎回答：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_insert_sql</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment">#插入知乎回答表的sql语句</span></span><br><span class="line">    insert_sql = <span class="string">"""</span></span><br><span class="line"><span class="string">        insert into zhihu_answer(zhihu_id, url, question_id, author_id, content, parise_num, comments_num,</span></span><br><span class="line"><span class="string">          create_time, update_time, crawl_time</span></span><br><span class="line"><span class="string">          ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)</span></span><br><span class="line"><span class="string">          ON DUPLICATE KEY UPDATE content=VALUES(content), comments_num=VALUES(comments_num), parise_num=VALUES(parise_num),</span></span><br><span class="line"><span class="string">          update_time=VALUES(update_time)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    create_time = datetime.datetime.fromtimestamp(self[<span class="string">"create_time"</span>]).strftime(SQL_DATETIME_FORMAT)</span><br><span class="line">    update_time = datetime.datetime.fromtimestamp(self[<span class="string">"update_time"</span>]).strftime(SQL_DATETIME_FORMAT)</span><br><span class="line">    params = (</span><br><span class="line">        self[<span class="string">"zhihu_id"</span>], self[<span class="string">"url"</span>], self[<span class="string">"question_id"</span>],</span><br><span class="line">        self[<span class="string">"author_id"</span>], self[<span class="string">"content"</span>], self[<span class="string">"parise_num"</span>],</span><br><span class="line">        self[<span class="string">"comments_num"</span>], create_time, update_time,</span><br><span class="line">        self[<span class="string">"crawl_time"</span>].strftime(SQL_DATETIME_FORMAT),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> insert_sql, params</span><br></pre></td></tr></table></figure><p><strong>第二次爬取到相同数据，更新数据</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ON DUPLICATE KEY <span class="keyword">UPDATE</span> <span class="keyword">content</span>=<span class="keyword">VALUES</span>(<span class="keyword">content</span>), answer_num=<span class="keyword">VALUES</span>(answer_num), comments_num=<span class="keyword">VALUES</span>(comments_num),</span><br><span class="line">              watch_user_num=<span class="keyword">VALUES</span>(watch_user_num), click_num=<span class="keyword">VALUES</span>(click_num)</span><br></pre></td></tr></table></figure><p><strong>调试技巧</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> match_obj:</span><br><span class="line">    <span class="comment">#如果提取到question相关的页面则下载后交由提取函数进行提取</span></span><br><span class="line">    request_url = match_obj.group(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">yield</span> scrapy.Request(request_url, headers=self.headers, callback=self.parse_question)</span><br><span class="line">    <span class="comment">#方便调试</span></span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment">#方便调试</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">    <span class="comment">#如果不是question页面则直接进一步跟踪</span></span><br><span class="line">    <span class="comment">#方便调试</span></span><br><span class="line">    <span class="comment"># yield scrapy.Request(url, headers=self.headers, callback=self.parse)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方便调试</span></span><br><span class="line">    <span class="comment"># yield question_item</span></span><br></pre></td></tr></table></figure><p><strong>错误排查</strong><br>[key error] title<br>pipeline中debug定位到哪一个item的错误。</p></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><div><div class="my_post_copyright"><script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script><script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script><script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script><p><span>本文标题:</span><a href="/post/b9bf70b2.html">Scrapy分布式爬虫打造搜索引擎- (三)知乎网问题和答案爬取</a></p><p><span>文章作者:</span><a href="/" title="访问 mtianyan 的个人博客">mtianyan</a></p><p><span>发布时间:</span>2017年06月28日 - 14:06</p><p><span>最后更新:</span>2018年01月06日 - 06:01</p><p><span>原始链接:</span><a href="/post/b9bf70b2.html" title="Scrapy分布式爬虫打造搜索引擎- (三)知乎网问题和答案爬取">http://blog.mtianyan.cn/post/b9bf70b2.html</a><span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://blog.mtianyan.cn/post/b9bf70b2.html" aria-label="复制成功！"></i></span></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p></div><script>var clipboard=new Clipboard(".fa-clipboard");$(".fa-clipboard").click(function(){clipboard.on("success",function(){swal({title:"",text:"复制成功",icon:"success",showConfirmButton:!0})})})</script></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>请博主吃包辣条</div> <button id="rewardButton" disable="enable" onclick='var qr=document.getElementById("QR");"none"===qr.style.display?qr.style.display="block":qr.style.display="none"'> <span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"> <img id="wechat_qr" src="/images/wechatpay.png" alt="mtianyan 微信支付"><p>微信支付</p></div><div id="alipay" style="display:inline-block"> <img id="alipay_qr" src="/images/alipay.jpg" alt="mtianyan 支付宝"><p>支付宝</p></div></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a><a href="/tags/爬虫/" rel="tag"><i class="fa fa-tag"></i> 爬虫</a><a href="/tags/搜索引擎/" rel="tag"><i class="fa fa-tag"></i> 搜索引擎</a><a href="/tags/Scrapy/" rel="tag"><i class="fa fa-tag"></i> Scrapy</a></div><div class="post-widgets"><div id="needsharebutton-postbottom"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/post/1cc4531e.html" rel="next" title="Scrapy分布式爬虫打造搜索引擎- (二)伯乐在线爬取所有文章"><i class="fa fa-chevron-left"></i> Scrapy分布式爬虫打造搜索引擎- (二)伯乐在线爬取所有文章</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/post/d083b798.html" rel="prev" title="Scrapy分布式爬虫打造搜索引擎- (四)通过CrawlSpider对拉勾网进行整站爬取">Scrapy分布式爬虫打造搜索引擎- (四)通过CrawlSpider对拉勾网进行整站爬取<i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"><div class="jiathis_style"> <span class="jiathis_txt">分享到：</span> <a class="jiathis_button_fav">收藏夹</a> <a class="jiathis_button_copy">复制网址</a> <a class="jiathis_button_email">邮件</a> <a class="jiathis_button_weixin">微信</a> <a class="jiathis_button_qzone">QQ空间</a> <a class="jiathis_button_tqq">腾讯微博</a> <a class="jiathis_button_douban">豆瓣</a> <a class="jiathis_button_share">一键分享</a> <a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a><a class="jiathis_counter_style"></a></div><script type="text/javascript">var jiathis_config={data_track_clickback:!0,summary:"",shortUrl:!1,hideMore:!1}</script><script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=2154292" charset="utf-8"></script></div></div></div><div class="comments" id="comments"><div id="SOHUCS"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap"> 站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="mtianyan"><p class="site-author-name" itemprop="name">mtianyan</p><p class="site-description motion-element" itemprop="description">爱分享，爱技术，爱生活。</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/index.html"><span class="site-state-item-count">4</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/index.html"><span class="site-state-item-count">20</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/mtianyan" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i> GitHub</a></span><span class="links-of-author-item"><a href="https://www.jianshu.com/u/db9a7a0daa1f" target="_blank" title="简书"><i class="fa fa-fw fa-book"></i> 简书</a></span><span class="links-of-author-item"><a href="https://plus.google.com/u/0/114963812195952881148" target="_blank" title="Google"><i class="fa fa-fw fa-google"></i> Google</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="http://mtianyan.gitee.io/" title="本站孪生站(国内码云托管)" target="_blank">本站孪生站(国内码云托管)</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-基础知识"><span class="nav-number">1.</span> <span class="nav-text">1. 基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#session和cookie机制"><span class="nav-number">1.1.</span> <span class="nav-text">session和cookie机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#request模拟知乎的登录"><span class="nav-number">1.2.</span> <span class="nav-text">request模拟知乎的登录</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-scrapy创建知乎爬虫登录"><span class="nav-number">2.</span> <span class="nav-text">2. scrapy创建知乎爬虫登录</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#将item写入数据库"><span class="nav-number">2.1.</span> <span class="nav-text">将item写入数据库</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2018</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">mtianyan</span><div class="theme-info"><div class="powered-by"></div> <span class="post-count">博客全站共97.6k字</span></div></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script> <span class="site-uv">本站访客数<span class="busuanzi-value" id="busuanzi_value_site_uv"></span> 人次</span> <span class="site-pv">本站总访问量<span class="busuanzi-value" id="busuanzi_value_site_pv"></span> 次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div><div id="needsharebutton-float"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script><script type="text/javascript">!function(){var t="1eb79150519fd9b791c77e8eef6f3632";if((window.innerWidth||document.documentElement.clientWidth)<960)window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=cyrJmJ3rL&conf='+t+'"><\/script>');else{!function(t,e){var n=document.getElementsByTagName("head")[0]||document.head||document.documentElement,a=document.createElement("script");a.setAttribute("type","text/javascript"),a.setAttribute("charset","UTF-8"),a.setAttribute("src",t),"function"==typeof e&&(window.attachEvent?a.onreadystatechange=function(){var t=a.readyState;"loaded"!==t&&"complete"!==t||(a.onreadystatechange=null,e())}:a.onload=e),n.appendChild(a)}("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:"cyrJmJ3rL",conf:t})})}}()</script><script type="text/javascript" src="https://assets.changyan.sohu.com/upload/plugins/plugins.count.js"></script><script type="text/javascript">var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(t){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")};function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var t=$("#local-search-input");t.attr("autocapitalize","none"),t.attr("autocorrect","off"),t.focus()}var searchFunc=function(t,e,o){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:t,dataType:isXml?"xml":"json",async:!0,success:function(t){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var n=isXml?$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():t,r=document.getElementById(e),s=document.getElementById(o),a=function(){var t=r.value.trim().toLowerCase(),e=t.split(/[\s\-]+/);e.length>1&&e.push(t);var o=[];if(t.length>0&&n.forEach(function(n){var r=!1,s=0,a=0,i=n.title.trim(),c=i.toLowerCase(),l=n.content.trim().replace(/<[^>]+>/g,""),h=l.toLowerCase(),p=decodeURIComponent(n.url),u=[],f=[];if(""!=i&&(e.forEach(function(t){function e(t,e,o){var n=t.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(e=e.toLowerCase(),t=t.toLowerCase());(s=e.indexOf(t,r))>-1;)a.push({position:s,word:t}),r=s+n;return a}u=u.concat(e(t,c,!1)),f=f.concat(e(t,h,!1))}),(u.length>0||f.length>0)&&(r=!0,s=u.length+f.length)),r){[u,f].forEach(function(t){t.sort(function(t,e){return e.position!==t.position?e.position-t.position:t.word.length-e.word.length})});function d(e,o,n,r){for(var s=r[r.length-1],i=s.position,c=s.word,l=[],h=0;i+c.length<=n&&0!=r.length;){c===t&&h++,l.push({position:i,length:c.length});var p=i+c.length;for(r.pop();0!=r.length&&(i=(s=r[r.length-1]).position,c=s.word,p>i);)r.pop()}return a+=h,{hits:l,start:o,end:n,searchTextCount:h}}var g=[];0!=u.length&&g.push(d(0,0,i.length,u));for(var v=[];0!=f.length;){var $=f[f.length-1],C=$.position,m=$.word,x=C-20,w=C+80;x<0&&(x=0),w<C+m.length&&(w=C+m.length),w>l.length&&(w=l.length),v.push(d(0,x,w,f))}v.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hits.length!==e.hits.length?e.hits.length-t.hits.length:t.start-e.start});var y=parseInt("1");y>=0&&(v=v.slice(0,y));function T(t,e){var o="",n=e.start;return e.hits.forEach(function(e){o+=t.substring(n,e.position);var r=e.position+e.length;o+='<b class="search-keyword">'+t.substring(e.position,r)+"</b>",n=r}),o+=t.substring(n,e.end)}var b="";0!=g.length?b+="<li><a href='"+p+"' class='search-result-title'>"+T(i,g[0])+"</a>":b+="<li><a href='"+p+"' class='search-result-title'>"+i+"</a>",v.forEach(function(t){b+="<a href='"+p+'\'><p class="search-result">'+T(l,t)+"...</p></a>"}),b+="</li>",o.push({item:b,searchTextCount:a,hitCount:s,id:o.length})}}),1===e.length&&""===e[0])s.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x" /></div>';else if(0===o.length)s.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';else{o.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hitCount!==e.hitCount?e.hitCount-t.hitCount:e.id-t.id});var a='<ul class="search-result-list">';o.forEach(function(t){a+=t.item}),a+="</ul>",s.innerHTML=a}};r.addEventListener("input",a),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(t){t.stopPropagation(),!1===isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(t){t.stopPropagation()}),$(document).on("keyup",function(t){27===t.which&&$(".search-popup").is(":visible")&&onPopupClose()})</script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script><script>AV.initialize("2uqmIjYredIvFy6tEXbKG4Fj-gzGzoHsz","CWl1rE8cQlIseOg2Cq3hzxYi")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0!==e.length){for(var i=0;i<e.length;i++){var s=e[i],r=s.get("url"),l=s.get("time"),c=document.getElementById(r);$(c).find(t).text(l)}for(i=0;i<n.length;i++){r=n[i],c=document.getElementById(r);var u=$(c).find(t);""==u.text()&&u.text(0)}}else o.find(t).text(0)}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){$(document.getElementById(n)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var s=new e,r=new AV.ACL;r.setPublicReadAccess(!0),r.setPublicWriteAccess(!0),s.setACL(r),s.set("title",o),s.set("url",n),s.set("time",1),s.save(null,{success:function(e){$(document.getElementById(n)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script><link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css"><script src="/lib/needsharebutton/needsharebutton.js"></script><script>pbOptions={},pbOptions.iconStyle="default",pbOptions.boxForm="horizontal",pbOptions.position="bottomCenter",pbOptions.networks="Weibo,Wechat,Douban,QQZone,Twitter,Facebook",new needShareButton("#needsharebutton-postbottom",pbOptions),flOptions={},flOptions.iconStyle="default",flOptions.boxForm="horizontal",flOptions.position="middleRight",flOptions.networks="Weibo,Wechat,Douban,QQZone,Twitter,Facebook",new needShareButton("#needsharebutton-float",flOptions)</script><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script><script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><div id="hexo-helper-live2d"><canvas id="live2dcanvas" width="150" height="300"></canvas></div><style>#live2dcanvas{position:fixed;width:150px;height:300px;opacity:.7;right:-30px;z-index:999;pointer-events:none;bottom:40px}</style><script type="text/javascript" src="/live2d/device.min.js"></script><script type="text/javascript">
const loadScript = function loadScript(c,b){var a=document.createElement("script");a.type="text/javascript";"undefined"!=typeof b&&(a.readyState?a.onreadystatechange=function(){if("loaded"==a.readyState||"complete"==a.readyState)a.onreadystatechange=null,b()}:a.onload=function(){b()});a.src=c;document.body.appendChild(a)};
(function(){
  if((typeof(device) != 'undefined') && (device.mobile())){
    var trElement = document.getElementById('hexo-helper-live2d');
    trElement.parentNode.removeChild(trElement);
    return;
  }else
    if (typeof(device) === 'undefined') console.error('Cannot find current-device script.');
  loadScript("/live2d/script.js", function(){loadlive2d("live2dcanvas", "/live2d/assets/hijiki.model.json", 0.5);});
})();
</script></body></html><script type="text/javascript" src="/js/src/love.js"></script>